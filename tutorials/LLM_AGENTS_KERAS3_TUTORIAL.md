# LLM Agents Tutorial: Mastering Autonomous AI Systems from First Principles

## ðŸ“š Welcome to the Complete LLM Agents Learning Journey!

This comprehensive tutorial transforms you from someone who uses language models into an **LLM agents expert** who can build sophisticated autonomous AI systems. You'll master the theoretical foundations, implement agent architectures from scratch, understand tool usage patterns, and create production-ready multi-agent systems integrated with your actual chat platform.

**What Makes This Tutorial Unique:**
- **Complete Self-Contained Learning**: From agent theory to production autonomous systems
- **Build From Scratch**: Implement every agent pattern and tool interface manually
- **Theory + Practice**: Deep understanding of agent reasoning combined with hands-on coding
- **Real Integration**: Apply advanced agent techniques to your actual working platform
- **Cutting-Edge Architectures**: Latest advances in ReAct, planning, and multi-agent systems

### **The AI Agents Revolution: Understanding Autonomous Intelligence**

LLM Agents represent the next evolutionary step beyond language models. While LLMs can understand and generate text, agents can **reason, plan, and act** in the world. They transform static AI assistants into dynamic, goal-oriented systems that can operate autonomously to achieve complex objectives.

**Historical Context:**
- **2022**: ReAct pattern introduces reasoning and acting in language models
- **2023**: AutoGPT demonstrates autonomous task execution capabilities
- **2023**: LangChain enables tool-using agents at scale
- **2024**: Multi-agent systems show emergent collaborative intelligence
- **Today**: Building foundations for artificial general intelligence through agents

**Why Agent Mastery Matters:**
- **Beyond Conversation**: Move from reactive chat to proactive assistance
- **Autonomous Capabilities**: Build systems that operate independently
- **Complex Problem Solving**: Handle multi-step reasoning and execution
- **Real-World Impact**: Create AI that interacts with external systems
- **Future-Proof Skills**: Foundation for AGI and advanced AI systems

---

## ðŸŽ¯ Complete Learning Objectives

### **Chapter 1: Foundations of AI Agents**
**Learning Goals:**
- Understand the mathematical foundations of agent behavior
- Master the difference between reactive and deliberative agents
- Learn agent architectures and reasoning patterns
- Grasp the theoretical framework of autonomous systems

**What You'll Be Able to Do:**
- Design agent architectures for specific problem domains
- Implement basic agent reasoning loops from scratch
- Understand agent evaluation metrics and performance measures
- Debug agent behavior and improve decision-making processes

### **Chapter 2: Tool Usage and Interface Patterns**
**Learning Goals:**
- Master different tool interface formats (JSON, functions, APIs)
- Understand tool discovery and dynamic binding mechanisms
- Learn error handling and recovery in tool usage
- Implement secure and robust tool execution systems

**What You'll Be Able to Do:**
- Design flexible tool interfaces for various systems
- Implement secure tool execution with proper error handling
- Create dynamic tool discovery and binding systems
- Build tool usage monitoring and optimization systems

### **Chapter 3: Advanced Agent Architectures**
**Learning Goals:**
- Master ReAct (Reasoning and Acting) pattern implementation
- Understand planning agents and goal decomposition
- Learn memory systems and long-term context management
- Implement learning and adaptation mechanisms

**What You'll Be Able to Do:**
- Build sophisticated reasoning agents that plan and execute
- Implement memory systems for complex task management
- Create adaptive agents that improve over time
- Design agent architectures for specific domain requirements

### **Chapter 4: Multi-Agent Systems**
**Learning Goals:**
- Understand agent communication protocols and coordination
- Master distributed problem solving and task allocation
- Learn emergent behavior in multi-agent systems
- Implement conflict resolution and consensus mechanisms

**What You'll Be Able to Do:**
- Design multi-agent architectures for complex systems
- Implement agent communication and coordination protocols
- Create distributed problem-solving systems
- Build fault-tolerant multi-agent networks

### **Chapter 5: Production Agent Systems**
**Learning Goals:**
- Master agent deployment and monitoring in production
- Understand scalability and performance optimization
- Learn safety, security, and alignment considerations
- Implement agent system management and orchestration

**What You'll Be Able to Do:**
- Deploy autonomous agent systems at scale
- Monitor and optimize agent performance in production
- Implement safety measures and alignment techniques
- Build complete agent platforms with management interfaces

---

## ðŸ§  Chapter 0: Mathematical Foundations of Agent Systems

Before building agents, we need to understand the mathematical and theoretical foundations that make autonomous behavior possible. This groundwork will make everything else crystal clear.

### Understanding Agent Behavior Mathematically

**An Agent as a Mathematical Function:**

At its core, an agent is a function that maps observations to actions over time:

```
Agent: (Observation Ã— Memory) â†’ (Action Ã— Updated_Memory)
```

More formally, an agent can be represented as:
```
Ï€Î¸(at | ot, mt) = P(action_at_time_t | observation_at_time_t, memory_at_time_t)
```

Where Î¸ represents the agent's parameters (learned through training or hardcoded rules).

**The Agent-Environment Loop:**

```python
# fundamental_agent_theory.py - Mathematical foundations of agents
import numpy as np
from typing import Any, Dict, List, Tuple, Optional
from abc import ABC, abstractmethod

class Environment:
    """
    Abstract environment that agents interact with.
    
    This represents the mathematical concept of an environment
    in agent theory - anything the agent can observe and act upon.
    """
    
    def __init__(self):
        self.state = None
        self.history = []
    
    def step(self, action: Any) -> Tuple[Any, float, bool, Dict]:
        """
        Execute action and return (observation, reward, done, info).
        
        This is the fundamental environment interface:
        - observation: What the agent can perceive
        - reward: Feedback signal for the action
        - done: Whether the episode is complete
        - info: Additional environment information
        """
        raise NotImplementedError
    
    def reset(self) -> Any:
        """Reset environment and return initial observation."""
        raise NotImplementedError

class Agent(ABC):
    """
    Abstract agent following the mathematical agent definition.
    
    An agent perceives environment state and takes actions
    to maximize some objective function over time.
    """
    
    def __init__(self, name: str):
        self.name = name
        self.memory = {}
        self.action_history = []
        self.observation_history = []
    
    @abstractmethod
    def perceive(self, observation: Any) -> None:
        """Process observation and update internal state."""
        pass
    
    @abstractmethod
    def decide(self) -> Any:
        """Decide on next action based on current state."""
        pass
    
    @abstractmethod
    def act(self, action: Any) -> Any:
        """Execute action in environment."""
        pass
    
    def agent_loop(self, environment: Environment, max_steps: int = 1000):
        """
        Execute the fundamental agent-environment interaction loop.
        
        This implements the core mathematical relationship:
        observation â†’ reasoning â†’ action â†’ environment response â†’ repeat
        """
        
        observation = environment.reset()
        total_reward = 0
        
        for step in range(max_steps):
            # Perceive current state
            self.perceive(observation)
            
            # Decide on action
            action = self.decide()
            
            # Act in environment
            observation, reward, done, info = environment.step(action)
            total_reward += reward
            
            # Update history
            self.action_history.append(action)
            self.observation_history.append(observation)
            
            if done:
                break
        
        return total_reward, step + 1

def demonstrate_agent_mathematics():
    """
    Demonstrate the mathematical foundations of agent behavior.
    """
    
    print("ðŸ§® Mathematical Foundations of AI Agents")
    print("=" * 50)
    
    # Define different types of agent decision functions
    
    def reactive_agent(observation):
        """
        Reactive agent: action = f(current_observation)
        No memory, purely stimulus-response
        """
        # Simple rule-based response
        if "help" in str(observation).lower():
            return "provide_help"
        elif "analyze" in str(observation).lower():
            return "perform_analysis"
        else:
            return "default_response"
    
    def deliberative_agent(observation, memory):
        """
        Deliberative agent: action = f(observation, memory, goals)
        Uses internal state and planning
        """
        # Update memory with observation
        memory['observations'] = memory.get('observations', [])
        memory['observations'].append(observation)
        
        # Deliberate based on history and goals
        if len(memory['observations']) > 3:
            # If we've seen multiple observations, plan multi-step response
            return "complex_planned_action"
        else:
            return "simple_response"
    
    def learning_agent(observation, memory, experience):
        """
        Learning agent: action = f(observation, memory, learned_policy)
        Adapts behavior based on past outcomes
        """
        # Update memory
        memory['total_interactions'] = memory.get('total_interactions', 0) + 1
        
        # Learn from experience (simplified)
        success_rate = experience.get('success_rate', 0.5)
        
        if success_rate > 0.7:
            return "confident_action"
        elif success_rate < 0.3:
            return "cautious_action"
        else:
            return "exploratory_action"
    
    # Demonstrate different agent types
    sample_observation = "User needs help analyzing data"
    sample_memory = {}
    sample_experience = {'success_rate': 0.8}
    
    print("Agent Decision Comparison:")
    print(f"Observation: '{sample_observation}'")
    print()
    
    reactive_action = reactive_agent(sample_observation)
    print(f"Reactive Agent:     {reactive_action}")
    print("  - Decision based only on current observation")
    print("  - No memory or learning")
    
    deliberative_action = deliberative_agent(sample_observation, sample_memory.copy())
    print(f"Deliberative Agent: {deliberative_action}")
    print("  - Decision based on observation + memory")
    print("  - Can plan multi-step actions")
    
    learning_action = learning_agent(sample_observation, sample_memory.copy(), sample_experience)
    print(f"Learning Agent:     {learning_action}")
    print("  - Decision based on observation + memory + experience")
    print("  - Adapts behavior based on past outcomes")
    
    print(f"\nðŸ” Key Insight: More sophisticated agents consider more information")
    print(f"  Reactive: O(1) - constant time decisions")
    print(f"  Deliberative: O(n) - proportional to memory size") 
    print(f"  Learning: O(n + m) - memory + experience")

demonstrate_agent_mathematics()
```

### The Information Theory of Agent Decision Making

**Decision Making as Information Processing:**

Agent decisions can be understood through information theory:

```python
def analyze_agent_information_processing():
    """
    Analyze agent decision-making from an information theory perspective.
    
    This helps us understand why certain agent architectures work better
    than others for different types of problems.
    """
    
    import math
    
    print("\nðŸ“Š Information Theory of Agent Decisions")
    print("=" * 50)
    
    # Simulate different agent information processing capabilities
    
    def calculate_decision_entropy(possible_actions, action_probabilities):
        """Calculate entropy of agent's decision distribution."""
        entropy = 0
        for prob in action_probabilities:
            if prob > 0:
                entropy -= prob * math.log2(prob)
        return entropy
    
    # Example scenarios
    scenarios = {
        "Simple Task": {
            "actions": ["yes", "no"],
            "reactive_probs": [0.9, 0.1],        # High confidence, low entropy
            "deliberative_probs": [0.7, 0.3],    # Moderate confidence
            "learning_probs": [0.95, 0.05]       # Very high confidence after learning
        },
        "Complex Task": {
            "actions": ["plan_a", "plan_b", "plan_c", "wait", "ask_for_help"],
            "reactive_probs": [0.2, 0.2, 0.2, 0.2, 0.2],    # High entropy, confused
            "deliberative_probs": [0.5, 0.3, 0.1, 0.05, 0.05], # Lower entropy, more confident
            "learning_probs": [0.8, 0.1, 0.05, 0.03, 0.02]     # Lowest entropy, learned optimal
        }
    }
    
    for scenario_name, scenario in scenarios.items():
        print(f"\nðŸ“‹ Scenario: {scenario_name}")
        actions = scenario["actions"]
        
        for agent_type in ["reactive", "deliberative", "learning"]:
            probs = scenario[f"{agent_type}_probs"]
            entropy = calculate_decision_entropy(actions, probs)
            
            # Calculate information content (surprise)
            max_entropy = math.log2(len(actions))  # Maximum possible entropy
            confidence = 1 - (entropy / max_entropy)  # Confidence as inverse of normalized entropy
            
            print(f"  {agent_type.capitalize():<12}: entropy={entropy:.2f}, confidence={confidence:.2f}")
    
    print(f"\nðŸ’¡ Key Insights:")
    print(f"  - Lower entropy = more confident decisions")
    print(f"  - Learning agents develop lower entropy over time")
    print(f"  - Complex tasks require deliberative processing")
    print(f"  - Information processing capacity limits agent performance")

analyze_agent_information_processing()
```

### The Cognitive Architecture of Reasoning

**Understanding Different Reasoning Patterns:**

LLM agents use different reasoning patterns depending on the task:

```python
class ReasoningPattern:
    """
    Base class for different reasoning patterns used by LLM agents.
    
    Each pattern represents a different way of processing information
    and making decisions.
    """
    
    def __init__(self, name: str):
        self.name = name
        self.steps = []
    
    def reason(self, problem: str) -> List[str]:
        """Apply reasoning pattern to a problem."""
        raise NotImplementedError

class ChainOfThoughtReasoning(ReasoningPattern):
    """
    Chain-of-Thought: Step-by-step reasoning through problems.
    
    This pattern breaks complex problems into sequential steps,
    making the reasoning process explicit and traceable.
    """
    
    def __init__(self):
        super().__init__("Chain-of-Thought")
    
    def reason(self, problem: str) -> List[str]:
        """
        Apply chain-of-thought reasoning.
        
        Steps:
        1. Understand the problem
        2. Break into sub-problems  
        3. Solve each sub-problem
        4. Combine solutions
        """
        
        reasoning_steps = [
            f"Problem: {problem}",
            "Step 1: Let me understand what's being asked...",
            "Step 2: I need to break this into smaller parts...", 
            "Step 3: For each part, I'll...",
            "Step 4: Combining these solutions..."
        ]
        
        return reasoning_steps

class ReActReasoning(ReasoningPattern):
    """
    ReAct: Reasoning + Acting pattern.
    
    This pattern interleaves reasoning (thought) with actions (tool use),
    allowing agents to gather information and act on it iteratively.
    """
    
    def __init__(self):
        super().__init__("ReAct")
        self.available_tools = ["search", "calculate", "analyze", "execute"]
    
    def reason(self, problem: str) -> List[str]:
        """
        Apply ReAct reasoning pattern.
        
        Alternates between:
        - Thought: reasoning about the problem
        - Action: using tools to gather information or execute
        - Observation: processing results of actions
        """
        
        reasoning_steps = [
            f"Problem: {problem}",
            "Thought: I need to understand this problem better.",
            "Action: search(problem context)",
            "Observation: Found relevant information about...",
            "Thought: Based on this information, I should...", 
            "Action: calculate(specific computation)",
            "Observation: The calculation shows...",
            "Thought: Now I can provide a complete solution."
        ]
        
        return reasoning_steps

class PlanExecuteReasoning(ReasoningPattern):
    """
    Plan-Execute: High-level planning followed by detailed execution.
    
    This pattern separates strategic planning from tactical execution,
    allowing for better handling of complex, multi-step tasks.
    """
    
    def __init__(self):
        super().__init__("Plan-Execute")
    
    def reason(self, problem: str) -> List[str]:
        """
        Apply plan-execute reasoning.
        
        Steps:
        1. Create high-level plan
        2. Detail each step
        3. Execute steps sequentially
        4. Monitor and adapt
        """
        
        reasoning_steps = [
            f"Problem: {problem}",
            "Planning Phase:",
            "  - Goal: Define what success looks like",
            "  - Strategy: High-level approach",
            "  - Steps: Detailed action sequence",
            "Execution Phase:",
            "  - Step 1: Execute first action",
            "  - Step 2: Execute second action",
            "  - Monitor: Check progress against plan",
            "  - Adapt: Modify plan if needed"
        ]
        
        return reasoning_steps

def demonstrate_reasoning_patterns():
    """
    Demonstrate different reasoning patterns and their applications.
    """
    
    print("\nðŸ§  Cognitive Reasoning Patterns")
    print("=" * 50)
    
    # Create reasoning pattern instances
    patterns = [
        ChainOfThoughtReasoning(),
        ReActReasoning(), 
        PlanExecuteReasoning()
    ]
    
    # Test problem
    test_problem = "How can I optimize my portfolio to showcase advanced AI skills?"
    
    print(f"Test Problem: {test_problem}")
    print()
    
    for pattern in patterns:
        print(f"ðŸŽ¯ {pattern.name} Reasoning:")
        steps = pattern.reason(test_problem)
        
        for i, step in enumerate(steps):
            if step.startswith("  "):
                print(f"    {step}")
            else:
                print(f"  {step}")
        print()
    
    print("ðŸ” When to Use Each Pattern:")
    print("  Chain-of-Thought: Mathematical problems, logical reasoning")
    print("  ReAct: Information gathering, tool-using tasks")
    print("  Plan-Execute: Complex projects, multi-step objectives")
    print()
    print("ðŸ’¡ Advanced agents can switch between patterns based on task type")

demonstrate_reasoning_patterns()
```

---

## ðŸ” Chapter 1: Tool Usage and Interface Patterns

Tool usage is fundamental to agent capabilities. Agents need to interact with external systems, APIs, and functions to accomplish real-world tasks. Understanding different tool interface patterns is crucial for building practical agents.

### Understanding Tool Interface Formats

**The Tool Interface Spectrum:**

```python
# tool_interfaces.py - Complete guide to agent tool usage
import json
import inspect
from typing import Any, Dict, List, Callable, Optional
from dataclasses import dataclass
from enum import Enum

class ToolFormat(Enum):
    """Different formats for tool definitions and usage."""
    JSON_SCHEMA = "json_schema"           # OpenAI-style function calling
    PYTHON_FUNCTION = "python_function"   # Direct function calls
    REST_API = "rest_api"                 # HTTP API endpoints
    COMMAND_LINE = "command_line"         # Shell commands
    DATABASE = "database"                 # Database queries

@dataclass
class ToolResult:
    """Standardized result from tool execution."""
    success: bool
    data: Any
    error: Optional[str] = None
    metadata: Optional[Dict] = None

class Tool:
    """
    Base tool class supporting multiple interface formats.
    
    This provides a unified interface for tools regardless of their
    underlying implementation (JSON, functions, APIs, etc.).
    """
    
    def __init__(self, name: str, description: str, format_type: ToolFormat):
        self.name = name
        self.description = description
        self.format_type = format_type
        self.usage_count = 0
        self.success_count = 0
    
    def execute(self, *args, **kwargs) -> ToolResult:
        """Execute the tool with given parameters."""
        self.usage_count += 1
        try:
            result = self._execute_impl(*args, **kwargs)
            self.success_count += 1
            return ToolResult(success=True, data=result)
        except Exception as e:
            return ToolResult(success=False, data=None, error=str(e))
    
    def _execute_impl(self, *args, **kwargs) -> Any:
        """Subclass-specific implementation."""
        raise NotImplementedError
    
    def get_schema(self) -> Dict:
        """Get tool schema for agent understanding."""
        raise NotImplementedError
    
    def get_success_rate(self) -> float:
        """Calculate tool success rate."""
        if self.usage_count == 0:
            return 0.0
        return self.success_count / self.usage_count

class JSONSchemaTool(Tool):
    """
    JSON Schema tool following OpenAI function calling format.
    
    This format is used by many LLM APIs and provides structured
    parameter definitions with validation.
    """
    
    def __init__(self, name: str, description: str, parameters: Dict, function: Callable):
        super().__init__(name, description, ToolFormat.JSON_SCHEMA)
        self.parameters = parameters
        self.function = function
    
    def get_schema(self) -> Dict:
        """Return OpenAI-compatible function schema."""
        return {
            "name": self.name,
            "description": self.description,
            "parameters": self.parameters
        }
    
    def _execute_impl(self, **kwargs) -> Any:
        """Execute using JSON parameters."""
        return self.function(**kwargs)

class PythonFunctionTool(Tool):
    """
    Direct Python function tool.
    
    This format allows agents to call Python functions directly,
    with automatic parameter inspection and validation.
    """
    
    def __init__(self, function: Callable):
        name = function.__name__
        description = function.__doc__ or f"Python function: {name}"
        super().__init__(name, description, ToolFormat.PYTHON_FUNCTION)
        self.function = function
        self.signature = inspect.signature(function)
    
    def get_schema(self) -> Dict:
        """Auto-generate schema from function signature."""
        parameters = {
            "type": "object",
            "properties": {},
            "required": []
        }
        
        for param_name, param in self.signature.parameters.items():
            param_info = {"type": "string"}  # Default type
            
            # Try to infer type from annotation
            if param.annotation != inspect.Parameter.empty:
                if param.annotation == int:
                    param_info["type"] = "integer"
                elif param.annotation == float:
                    param_info["type"] = "number"
                elif param.annotation == bool:
                    param_info["type"] = "boolean"
            
            parameters["properties"][param_name] = param_info
            
            # Check if parameter is required
            if param.default == inspect.Parameter.empty:
                parameters["required"].append(param_name)
        
        return {
            "name": self.name,
            "description": self.description,
            "parameters": parameters
        }
    
    def _execute_impl(self, *args, **kwargs) -> Any:
        """Execute Python function directly."""
        return self.function(*args, **kwargs)

class RestAPITool(Tool):
    """
    REST API tool for external service integration.
    
    This format allows agents to interact with web services,
    handling authentication, retries, and error recovery.
    """
    
    def __init__(self, name: str, description: str, base_url: str, 
                 method: str = "GET", headers: Optional[Dict] = None):
        super().__init__(name, description, ToolFormat.REST_API)
        self.base_url = base_url
        self.method = method
        self.headers = headers or {}
    
    def get_schema(self) -> Dict:
        """Return API schema."""
        return {
            "name": self.name,
            "description": self.description,
            "parameters": {
                "type": "object",
                "properties": {
                    "endpoint": {"type": "string", "description": "API endpoint path"},
                    "params": {"type": "object", "description": "Query parameters"},
                    "data": {"type": "object", "description": "Request body data"}
                },
                "required": ["endpoint"]
            }
        }
    
    def _execute_impl(self, endpoint: str, params: Optional[Dict] = None, 
                      data: Optional[Dict] = None) -> Any:
        """Execute API request."""
        # Simplified implementation - in practice, use requests library
        url = f"{self.base_url}/{endpoint.lstrip('/')}"
        
        # Mock API response for demonstration
        return {
            "url": url,
            "method": self.method,
            "params": params,
            "data": data,
            "response": "Mock API response"
        }

def create_example_tools():
    """
    Create example tools showcasing different formats.
    
    These tools demonstrate how agents can interact with
    various types of external systems and services.
    """
    
    print("ðŸ› ï¸ Tool Interface Formats")
    print("=" * 40)
    
    # 1. JSON Schema Tool (OpenAI-style)
    def analyze_portfolio(projects: List[str], skills: List[str], goal: str) -> Dict:
        """Analyze portfolio and suggest improvements."""
        return {
            "analysis": f"Analyzed {len(projects)} projects and {len(skills)} skills",
            "recommendation": f"To achieve '{goal}', focus on advanced ML projects",
            "next_steps": ["Add transformer implementation", "Showcase production deployment"]
        }
    
    portfolio_tool = JSONSchemaTool(
        name="analyze_portfolio",
        description="Analyze portfolio and suggest improvements based on career goals",
        parameters={
            "type": "object",
            "properties": {
                "projects": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "List of current projects"
                },
                "skills": {
                    "type": "array", 
                    "items": {"type": "string"},
                    "description": "List of current skills"
                },
                "goal": {
                    "type": "string",
                    "description": "Career goal or objective"
                }
            },
            "required": ["projects", "skills", "goal"]
        },
        function=analyze_portfolio
    )
    
    # 2. Python Function Tool (direct function)
    def calculate_learning_progress(completed_tutorials: int, total_tutorials: int, 
                                  hours_spent: float) -> Dict:
        """Calculate learning progress metrics."""
        completion_rate = completed_tutorials / total_tutorials if total_tutorials > 0 else 0
        average_time = hours_spent / completed_tutorials if completed_tutorials > 0 else 0
        
        return {
            "completion_percentage": completion_rate * 100,
            "tutorials_remaining": total_tutorials - completed_tutorials,
            "average_hours_per_tutorial": average_time,
            "estimated_time_remaining": average_time * (total_tutorials - completed_tutorials)
        }
    
    learning_tool = PythonFunctionTool(calculate_learning_progress)
    
    # 3. REST API Tool (external service)
    system_monitor = RestAPITool(
        name="monitor_system",
        description="Monitor system performance and resource usage",
        base_url="http://localhost:5000/api",
        method="GET",
        headers={"Authorization": "Bearer token"}
    )
    
    tools = [portfolio_tool, learning_tool, system_monitor]
    
    # Demonstrate tool schemas
    print("ðŸ“‹ Tool Schemas:")
    for tool in tools:
        print(f"\n{tool.name} ({tool.format_type.value}):")
        schema = tool.get_schema()
        print(f"  Description: {schema['description']}")
        if 'parameters' in schema:
            print(f"  Parameters: {len(schema['parameters'].get('properties', {}))} defined")
    
    # Demonstrate tool execution
    print(f"\nâš¡ Tool Execution Examples:")
    
    # Execute JSON Schema tool
    result1 = portfolio_tool.execute(
        projects=["Chat Platform", "TinyML System", "Transformer Implementation"],
        skills=["Python", "Keras", "Flask", "React"],
        goal="Senior AI Engineer position"
    )
    print(f"\n{portfolio_tool.name}: {result1.success}")
    if result1.success:
        print(f"  Recommendation: {result1.data['recommendation']}")
    
    # Execute Python function tool
    result2 = learning_tool.execute(
        completed_tutorials=3,
        total_tutorials=8,
        hours_spent=24.5
    )
    print(f"\n{learning_tool.name}: {result2.success}")
    if result2.success:
        print(f"  Progress: {result2.data['completion_percentage']:.1f}%")
        print(f"  Time remaining: {result2.data['estimated_time_remaining']:.1f} hours")
    
    # Execute REST API tool
    result3 = system_monitor.execute(
        endpoint="/status",
        params={"detailed": True}
    )
    print(f"\n{system_monitor.name}: {result3.success}")
    if result3.success:
        print(f"  Response: {result3.data['response']}")
    
    return tools

# Create and demonstrate tools
example_tools = create_example_tools()
```

### Dynamic Tool Discovery and Binding

**Advanced Tool Management:**

```python
class ToolRegistry:
    """
    Advanced tool registry with dynamic discovery and binding.
    
    This allows agents to discover available tools at runtime,
    bind to them dynamically, and manage tool lifecycle.
    """
    
    def __init__(self):
        self.tools: Dict[str, Tool] = {}
        self.categories: Dict[str, List[str]] = {}
        self.usage_stats: Dict[str, Dict] = {}
    
    def register_tool(self, tool: Tool, category: str = "general"):
        """Register a tool with the registry."""
        self.tools[tool.name] = tool
        
        if category not in self.categories:
            self.categories[category] = []
        self.categories[category].append(tool.name)
        
        self.usage_stats[tool.name] = {
            "registrations": 1,
            "last_used": None,
            "average_execution_time": 0.0
        }
        
        print(f"âœ… Registered tool: {tool.name} in category: {category}")
    
    def discover_tools(self, query: str) -> List[Tool]:
        """
        Discover relevant tools based on query.
        
        This uses semantic matching to find tools that might
        be relevant to the agent's current task.
        """
        relevant_tools = []
        query_lower = query.lower()
        
        for tool_name, tool in self.tools.items():
            # Simple keyword matching (in practice, use embeddings)
            if (query_lower in tool.name.lower() or 
                query_lower in tool.description.lower()):
                relevant_tools.append(tool)
        
        # Sort by success rate
        relevant_tools.sort(key=lambda t: t.get_success_rate(), reverse=True)
        
        return relevant_tools
    
    def get_tools_by_category(self, category: str) -> List[Tool]:
        """Get all tools in a specific category."""
        tool_names = self.categories.get(category, [])
        return [self.tools[name] for name in tool_names if name in self.tools]
    
    def get_tool_schema_collection(self) -> List[Dict]:
        """Get schemas for all registered tools."""
        return [tool.get_schema() for tool in self.tools.values()]
    
    def execute_tool(self, tool_name: str, **kwargs) -> ToolResult:
        """Execute a tool by name with error handling."""
        if tool_name not in self.tools:
            return ToolResult(
                success=False, 
                data=None, 
                error=f"Tool '{tool_name}' not found"
            )
        
        tool = self.tools[tool_name]
        
        # Update usage statistics
        import time
        start_time = time.time()
        
        result = tool.execute(**kwargs)
        
        execution_time = time.time() - start_time
        self.usage_stats[tool_name]["last_used"] = time.time()
        
        # Update average execution time
        current_avg = self.usage_stats[tool_name]["average_execution_time"]
        usage_count = tool.usage_count
        new_avg = ((current_avg * (usage_count - 1)) + execution_time) / usage_count
        self.usage_stats[tool_name]["average_execution_time"] = new_avg
        
        return result

def demonstrate_dynamic_tool_management():
    """
    Demonstrate dynamic tool discovery and management.
    """
    
    print("\nðŸ” Dynamic Tool Management")
    print("=" * 40)
    
    # Create tool registry
    registry = ToolRegistry()
    
    # Register tools from different categories
    
    # Portfolio management tools
    def update_portfolio(project_name: str, description: str, technologies: List[str]) -> Dict:
        """Add or update a project in the portfolio."""
        return {
            "project": project_name,
            "status": "updated",
            "tech_count": len(technologies),
            "last_modified": "2024-01-01"
        }
    
    registry.register_tool(
        PythonFunctionTool(update_portfolio),
        category="portfolio"
    )
    
    # System management tools  
    def check_system_health() -> Dict:
        """Check overall system health and performance."""
        return {
            "cpu_usage": 45.2,
            "memory_usage": 67.8,
            "disk_usage": 23.1,
            "status": "healthy"
        }
    
    registry.register_tool(
        PythonFunctionTool(check_system_health),
        category="system"
    )
    
    # Learning tools
    def track_tutorial_progress(tutorial_name: str, completion_percentage: float) -> Dict:
        """Track progress on a specific tutorial."""
        return {
            "tutorial": tutorial_name,
            "progress": completion_percentage,
            "estimated_completion": "2024-02-15",
            "next_milestone": "Chapter 5"
        }
    
    registry.register_tool(
        PythonFunctionTool(track_tutorial_progress), 
        category="learning"
    )
    
    print(f"ðŸ“š Tool Registry Status:")
    print(f"  Total tools: {len(registry.tools)}")
    print(f"  Categories: {list(registry.categories.keys())}")
    print(f"  Tools per category: {[(cat, len(tools)) for cat, tools in registry.categories.items()]}")
    
    # Demonstrate tool discovery
    print(f"\nðŸ” Tool Discovery Examples:")
    
    queries = [
        "portfolio management",
        "system monitoring", 
        "tutorial progress",
        "performance optimization"
    ]
    
    for query in queries:
        relevant_tools = registry.discover_tools(query)
        print(f"\nQuery: '{query}'")
        print(f"  Found {len(relevant_tools)} relevant tools:")
        for tool in relevant_tools:
            print(f"    - {tool.name}: {tool.description[:50]}...")
    
    # Demonstrate tool execution through registry
    print(f"\nâš¡ Tool Execution Through Registry:")
    
    result = registry.execute_tool(
        "track_tutorial_progress",
        tutorial_name="LLM Agents",
        completion_percentage=75.0
    )
    
    if result.success:
        print(f"âœ… Tutorial tracking: {result.data['progress']}% complete")
    else:
        print(f"âŒ Error: {result.error}")
    
    # Show usage statistics
    print(f"\nðŸ“Š Tool Usage Statistics:")
    for tool_name, stats in registry.usage_stats.items():
        tool = registry.tools[tool_name]
        print(f"  {tool_name}:")
        print(f"    Success rate: {tool.get_success_rate():.2f}")
        print(f"    Avg execution time: {stats['average_execution_time']:.3f}s")

demonstrate_dynamic_tool_management()
```

### Security and Error Handling in Tool Usage

**Production-Ready Tool Execution:**

```python
class SecureToolExecutor:
    """
    Secure tool executor with comprehensive error handling.
    
    This handles security, validation, retries, and monitoring
    for production agent systems.
    """
    
    def __init__(self, max_retries: int = 3, timeout: float = 30.0):
        self.max_retries = max_retries
        self.timeout = timeout
        self.execution_log = []
        self.security_policies = {}
    
    def add_security_policy(self, tool_name: str, policy: Dict):
        """Add security policy for a specific tool."""
        self.security_policies[tool_name] = policy
    
    def validate_parameters(self, tool: Tool, parameters: Dict) -> Tuple[bool, Optional[str]]:
        """Validate tool parameters against schema."""
        schema = tool.get_schema()
        
        if 'parameters' not in schema:
            return True, None
        
        required_params = schema['parameters'].get('required', [])
        provided_params = set(parameters.keys())
        required_set = set(required_params)
        
        missing_params = required_set - provided_params
        if missing_params:
            return False, f"Missing required parameters: {list(missing_params)}"
        
        return True, None
    
    def check_security_policy(self, tool_name: str, parameters: Dict) -> Tuple[bool, Optional[str]]:
        """Check if tool execution is allowed under security policy."""
        if tool_name not in self.security_policies:
            return True, None  # No policy = allowed
        
        policy = self.security_policies[tool_name]
        
        # Check rate limiting
        if 'max_calls_per_minute' in policy:
            recent_calls = len([
                log for log in self.execution_log 
                if (log['tool'] == tool_name and 
                    time.time() - log['timestamp'] < 60)
            ])
            
            if recent_calls >= policy['max_calls_per_minute']:
                return False, "Rate limit exceeded"
        
        # Check parameter restrictions
        if 'forbidden_params' in policy:
            forbidden = set(policy['forbidden_params']) & set(parameters.keys())
            if forbidden:
                return False, f"Forbidden parameters: {list(forbidden)}"
        
        return True, None
    
    def execute_with_retry(self, tool: Tool, parameters: Dict) -> ToolResult:
        """
        Execute tool with retry logic and comprehensive error handling.
        """
        import time
        
        tool_name = tool.name
        start_time = time.time()
        
        # Validate parameters
        valid, error = self.validate_parameters(tool, parameters)
        if not valid:
            return ToolResult(success=False, data=None, error=f"Validation error: {error}")
        
        # Check security policy
        allowed, error = self.check_security_policy(tool_name, parameters)
        if not allowed:
            return ToolResult(success=False, data=None, error=f"Security policy violation: {error}")
        
        # Execute with retries
        last_error = None
        for attempt in range(self.max_retries + 1):
            try:
                # Add timeout handling in practice
                result = tool.execute(**parameters)
                
                # Log execution
                self.execution_log.append({
                    'tool': tool_name,
                    'timestamp': time.time(),
                    'attempt': attempt + 1,
                    'success': result.success,
                    'execution_time': time.time() - start_time
                })
                
                if result.success:
                    return result
                else:
                    last_error = result.error
                    
            except Exception as e:
                last_error = str(e)
                
            # Wait before retry (exponential backoff)
            if attempt < self.max_retries:
                wait_time = 2 ** attempt  # 1s, 2s, 4s...
                time.sleep(wait_time)
        
        # All retries failed
        return ToolResult(
            success=False,
            data=None,
            error=f"Failed after {self.max_retries + 1} attempts. Last error: {last_error}"
        )
    
    def get_execution_stats(self) -> Dict:
        """Get execution statistics for monitoring."""
        if not self.execution_log:
            return {"total_executions": 0}
        
        total_executions = len(self.execution_log)
        successful_executions = sum(1 for log in self.execution_log if log['success'])
        
        execution_times = [log['execution_time'] for log in self.execution_log]
        avg_execution_time = sum(execution_times) / len(execution_times)
        
        tool_usage = {}
        for log in self.execution_log:
            tool_name = log['tool']
            if tool_name not in tool_usage:
                tool_usage[tool_name] = {'count': 0, 'success_count': 0}
            tool_usage[tool_name]['count'] += 1
            if log['success']:
                tool_usage[tool_name]['success_count'] += 1
        
        return {
            'total_executions': total_executions,
            'success_rate': successful_executions / total_executions,
            'average_execution_time': avg_execution_time,
            'tool_usage': tool_usage
        }

def demonstrate_secure_tool_execution():
    """
    Demonstrate secure tool execution with error handling.
    """
    
    print("\nðŸ”’ Secure Tool Execution")
    print("=" * 40)
    
    import time
    
    # Create secure executor
    executor = SecureToolExecutor(max_retries=2, timeout=10.0)
    
    # Create a tool that might fail
    def unreliable_tool(data: str, fail_rate: float = 0.3) -> Dict:
        """Tool that randomly fails to demonstrate retry logic."""
        import random
        if random.random() < fail_rate:
            raise Exception("Random failure for demonstration")
        return {"processed_data": data.upper(), "status": "success"}
    
    tool = PythonFunctionTool(unreliable_tool)
    
    # Add security policy
    executor.add_security_policy("unreliable_tool", {
        'max_calls_per_minute': 5,
        'forbidden_params': ['admin_mode']
    })
    
    print("ðŸ›¡ï¸ Security Policy Applied:")
    print("  - Max 5 calls per minute")
    print("  - 'admin_mode' parameter forbidden")
    
    # Test normal execution
    print("\nâœ… Normal Execution:")
    result1 = executor.execute_with_retry(tool, {"data": "test input", "fail_rate": 0.1})
    print(f"  Success: {result1.success}")
    if result1.success:
        print(f"  Result: {result1.data}")
    
    # Test parameter validation
    print("\nâŒ Parameter Validation Test:")
    result2 = executor.execute_with_retry(tool, {})  # Missing required parameter
    print(f"  Success: {result2.success}")
    print(f"  Error: {result2.error}")
    
    # Test security policy violation
    print("\nðŸš« Security Policy Test:")
    result3 = executor.execute_with_retry(tool, {
        "data": "test", 
        "admin_mode": True  # Forbidden parameter
    })
    print(f"  Success: {result3.success}")
    print(f"  Error: {result3.error}")
    
    # Test retry logic
    print("\nðŸ”„ Retry Logic Test:")
    result4 = executor.execute_with_retry(tool, {"data": "test", "fail_rate": 0.8})  # High failure rate
    print(f"  Success: {result4.success}")
    if not result4.success:
        print(f"  Error: {result4.error}")
    
    # Show execution statistics
    print("\nðŸ“Š Execution Statistics:")
    stats = executor.get_execution_stats()
    print(f"  Total executions: {stats['total_executions']}")
    print(f"  Success rate: {stats['success_rate']:.2f}")
    print(f"  Average execution time: {stats['average_execution_time']:.3f}s")

demonstrate_secure_tool_execution()
```

This comprehensive tool usage foundation provides:

1. **Multiple Interface Formats**: JSON Schema, Python functions, REST APIs
2. **Dynamic Tool Discovery**: Runtime tool finding and binding
3. **Security and Validation**: Production-ready safety measures
4. **Error Handling**: Comprehensive retry and recovery logic
5. **Monitoring**: Usage statistics and performance tracking

In the next chapters, we'll build on this foundation to create sophisticated agent architectures that can reason, plan, and coordinate using these tools. 